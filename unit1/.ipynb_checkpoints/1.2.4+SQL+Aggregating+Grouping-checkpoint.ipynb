{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating and grouping\n",
    "\n",
    "The simple but powerful queries you've learned about so far can be made even more powerful with grouping and aggregating. In SQL, grouping is about grouping database records according to some criteria. Aggregating is about applying one of many possible aggregating operations on a query â€” things like getting the max value in a column, or averaging out values in a certain range.\n",
    "\n",
    "For instance, you might have a table that records zip code, estimated home prices, last sold amount, and days on market for most recent sale. The following query would group by zipcode, returning the average estimated home price for the group and the max value for days on market for most recent sale.\n",
    "\n",
    "SELECT zipcode, AVG(estimated_home_price), MAX(days_on_market)\n",
    "FROM recent_sales\n",
    "GROUP BY zipcode;\n",
    "\n",
    "# The GROUP BY clause\n",
    "\n",
    "The GROUP BY statement comes after the WHERE clauses and before any ORDER BY clauses. Without any aggregation, grouping simply gets rid of duplicates, so all columns included in your select statement must also be included in your group by statement. Here's an example.\n",
    "\n",
    "SELECT\n",
    "    city\n",
    " FROM\n",
    "    stations\n",
    "GROUP BY city;\n",
    "\n",
    "That returns all the unique city names in the station table. Note that here we can also use numbers rather than names to reference columns. Since there is only one column, we could just do GROUP BY 1 instead of GROUP BY city in the example above. If we had selected three columns, we could GROUP BY 1,2,3, and so on.\n",
    "\n",
    "When doing this kind of grouping over multiple columns, the data is reduced to the unique values or combinations of values generated by the group by statement. Each unique group item gets a row in the output.\n",
    "\n",
    "# Aggregators\n",
    "\n",
    "Now let's talk about ways to use aggregator functions in SQL. By aggregators, we mean things that take a collection of values and return a single value. This can be things like the max or the average of a collection of values. You saw aggregator functions earlier in NumPy and Pandas, so this concept should ring a bell. Let's try it in a query.\n",
    "\n",
    "For this example, let's query for the mean latitude and longitude for stations in each city, as well as the station count. It's worth noting that when working with aggregators, the name of the column on your output defaults to the function you use to generate it. Those function names usually aren't very descriptive, so renaming columns is particularly useful when working with functions.\n",
    "\n",
    "SELECT\n",
    "    city,\n",
    "    AVG(lat) as latitude,\n",
    "    AVG(long) as longitude,\n",
    "    COUNT(*) as station_count\n",
    "FROM\n",
    "    stations\n",
    "GROUP by 1;\n",
    "\n",
    "-- We exclude columns that use aggregate functions from the group by\n",
    "-- clause, which is why we're only grouping by the city column.\n",
    "AVG takes the average of all of the values in the specified column with a given value in the grouped columns. COUNT(*) will count the number of rows with the given value in the grouped columns.\n",
    "\n",
    "At its core, grouping is as simple as that. Note that when using aggregate functions, every column in the query that doesn't use an aggregate function needs to be in the GROUP BY clause. A more complete list of aggregate functions for PostgreSQL can be found in the PostgreSQL aggregate function documentation.\n",
    "\n",
    "As we go further into SQL let's take a moment to talk about its role in data science. Beyond basic data selection, you could use Python to accomplish everything we're learning to do in SQL, just using SQL to create CSVs that you consume with Python. So why would we want to process data with SQL, and how do we choose when to use each tool?\n",
    "\n",
    "<p>There are many things to consider. The primary concern is the size of the data. SQL is much better suited to processing large data and the production database server is probably much beefier than your laptop running Python (there are some exceptions to this like using a distributed Python framework like Spark). As such SQL also tends to be much faster when working with large amounts of data than a local Python instance would be. SQL queries are also much lower weight to transfer across a network than a Python script plus a CSV or JSON dataset. Since SQL queries directly access the database they are also always accessing current data. SQL output is also easy to pipe into a Python environment or any <em>other</em> language, so if the output data might need to work with multiple languages, SQL is more robust than using Python.</p>\n",
    "\n",
    "<p>To some extent, how much to use SQL versus Python will remain a personal choice, and there are many scenarios where each is just as good as the other. Ultimately it will depend on the resources available and the complexity of your project.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drills\n",
    "\n",
    "What was the hottest day in our data set? Where was that?\n",
    "\n",
    "How many trips started at each station?\n",
    "\n",
    "What's the shortest trip that happened?\n",
    "\n",
    "What is the average trip duration, by end station?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.SELECT MaxTemperatureF, ZIP\n",
    "FROM weather\n",
    "ORDER BY 1 DESC\n",
    "LIMIT 1\n",
    "\n",
    "2.SELECT start_station, count(*) trips\n",
    "FROM trips\n",
    "GROUP BY start_station\n",
    "\n",
    "3.SELECT cast(duration as INT)\n",
    "FROM trips\n",
    "GROUP BY duration\n",
    "ORDER BY 1\n",
    "LIMIT 1\n",
    "\n",
    "4.SELECT end_station, AVG(duration) \n",
    "FROM trips\n",
    "GROUP BY end_station\n",
    "ORDER BY 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
