{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Continued\n",
    "We’ve introduced the core concept of a Naive Bayes Classifier, but there are still some details to sort out. In this section we’ll cover a bit of the decision process that goes into running the model, ways to improve performance, and some of the risks and downsides of using Naive Bayes.\n",
    "\n",
    "# Types of Naive Bayes\n",
    "When actually running a Naive Bayes classifier, you will have to make one more assumption. That assumption is around the distribution of P(xi|y).\n",
    "\n",
    "There are three main classifiers: Bernoulli, Multinomial, and Gaussian Naive Bayes. We’ve covered these distributions briefly in the fundamentals course. Each classifier assumes that the distribution of the conditional (the aforementioned P(xi|y)) is the given distribution.\n",
    "\n",
    "Now these distributions have limitations. A binomial only takes two possible values. A multinomial has discrete outcomes, and a Gaussian (also known as \"normal\") takes values along the continuous normal distribution.\n",
    "\n",
    "What this means is that choosing which kind of classifier you want to use depends on the distribution of your outcome variable. Choose the distribution that best fits your data. It should be pretty obvious, for instance, if it is best modeled using Bernoulli (the variable will be binary) and so on.\n",
    "\n",
    "If you’re interested in reading further about these types of Bayes classifiers, you can check out the scikit-learn documentation.\n",
    "\n",
    "# Improving Performance\n",
    "In running this kind of classifier, there are many things you can do to improve the performance of your model.\n",
    "\n",
    "The first and most important thing will be, as is often the case, feature engineering. This is particularly true in text based problems (which we’ll cover at greater length in the NLP section later in the course). Here it is largely up to the creativity and knowledge of the one building the model to draw out the right features.\n",
    "\n",
    "In Naive Bayes, feature selection can also be important. Because features are equally weighted, heavily correlated features can lead to doubling the impact of what is essentially a single feature. Remember, you’re making the assumption that every pair of variables is independent of each other. The more removed from that assumption reality is, the more problems you may run into.\n",
    "\n",
    "# Downsides of Naive Bayes\n",
    "The first and most obvious downside of Naive Bayes is that assumption of independence. That is a double edged sword because not only is it a condition you’ll often fail to have (even when the model works well), but it also means that any time two variables affect the outcome most in concert your model will fail to see it. This kind of effect is called interaction, and occurs when any two features create a different effect when they both have a specific value than they would as independent occurrences. In Naive Bayes any such interaction is lost.\n",
    "\n",
    "Also, Naive Bayes can only predict the outcome of categories it has seen before. This applies both to the outcome and the inputs. If you have new x-values in test, the model will default to ignoring that specific outcome. Like all classifiers it cannot predict a class it hasn’t seen. The way Naive Bayes handles partial data, however, does have the benefit of being indifferent to missing datapoints. Those missing datapoints simply get ignored, drawing what information it can from the other variables of that observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
