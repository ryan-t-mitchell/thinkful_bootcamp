{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap up\n",
    "You’ve now completed the sections of Decision Trees and Random Forests. You’ve covered a lot of ground. Specifically, you’re now familiar with:\n",
    "\n",
    "1. Decision Trees and the ID3 Algorithm\n",
    "2. Using Decision Trees to make Random Forests\n",
    "3. The strengths and weaknesses of Ensemble Modeling\n",
    "\n",
    "You’re going to use Random Forest a lot. They’re powerful and easy to run, at the cost of offering relatively little interpretability. They do parallelize nicely, leading them to be relatively efficient as well. Come back and play around with them again and again. Learning to make them as efficient as possible is a worthy way of spending your time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are advantages and disadvantages to ensemble models. Most notable is of course their performance. Ensemble models are often some of the most accurate techniques to apply to a problem. They also tend to have low variance because they're built from multiple internal models.\n",
    "\n",
    "However there are also downsides. Most notably, some ensemble techniques, particularly boosting, are prone to overfitting. You also lose a lot of the transparency that individual models offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
